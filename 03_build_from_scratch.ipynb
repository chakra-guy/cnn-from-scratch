{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3fdd69",
   "metadata": {},
   "source": [
    "# Level 3: Build from scratch\n",
    "\n",
    "In this final notebook, we strip away the framework (`tinygrad`) and implement the core CNN layers using only `numpy`. This proves we understand the mathematical operations happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f00f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(94)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f6dc5",
   "metadata": {},
   "source": [
    "## 1. Convolution (Conv2d)\n",
    "\n",
    "We will implement a naive 2D convolution using nested loops. Real frameworks use optimized matrix multiplications (im2col), but loops are easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed1606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d: Input (1, 1, 3, 3) -> Output (1, 1, 2, 2)\n",
      "Dummy Output:\n",
      "[[[[4. 4.]\n",
      "   [4. 4.]]]]\n"
     ]
    }
   ],
   "source": [
    "def conv2d_forward(input, weight, bias=None):\n",
    "    \"\"\"\n",
    "    Naive implementation of Conv2d.\n",
    "    input: (B, Cin, H, W)\n",
    "    weight: (Cout, Cin, K, K)\n",
    "    bias: (Cout)\n",
    "    \"\"\"\n",
    "    B, Cin, H, W = input.shape\n",
    "    Cout, _, K, _ = weight.shape\n",
    "\n",
    "    # Assuming stride=1, no padding for this demo\n",
    "    H_out = H - K + 1\n",
    "    W_out = W - K + 1\n",
    "\n",
    "    out = np.zeros((B, Cout, H_out, W_out))\n",
    "\n",
    "    print(f\"Conv2d: Input {input.shape} -> Output {out.shape}\")\n",
    "\n",
    "    for b in range(B):\n",
    "        for c_out in range(Cout):\n",
    "            for h in range(H_out):\n",
    "                for w in range(W_out):\n",
    "                    # Extract patch from input\n",
    "                    patch = input[b, :, h:h+K, w:w+K]\n",
    "                    # Dot product with weight filter\n",
    "                    # Sum over Cin, K, K\n",
    "                    val = np.sum(patch * weight[c_out])\n",
    "                    if bias is not None:\n",
    "                        val += bias[c_out]\n",
    "                    out[b, c_out, h, w] = val\n",
    "    return out\n",
    "\n",
    "# Verification\n",
    "x_dummy = np.ones((1, 1, 3, 3))\n",
    "w_dummy = np.ones((1, 1, 2, 2))\n",
    "out_dummy = conv2d_forward(x_dummy, w_dummy)\n",
    "print(f\"Dummy Output:\\n{out_dummy}\")\n",
    "# Expected: 4.0 in 2x2 grid (since 1*1 sum over 2x2 area is 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c02601",
   "metadata": {},
   "source": [
    "### Illustration: Edge Detection with Sobel Kernels\n",
    "\n",
    "The Sobel operator detects edges by computing image gradients in the X and Y directions. Our `conv2d_forward` function applies these kernels to find vertical and horizontal edges.\n",
    "\n",
    "![Convolution: Edge Detection with Sobel Kernels](images/conv2d_edge_detection.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8460ddb",
   "metadata": {},
   "source": [
    "## 2. ReLU Activation\n",
    "\n",
    "Rectified Linear Unit: returns `x` if `x > 0`, else `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b1beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU([-1, 0, 1]) = [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "def relu_forward(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Verification\n",
    "print(f\"ReLU([-1, 0, 1]) = {relu_forward(np.array([-1, 0, 1]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494531a",
   "metadata": {},
   "source": [
    "### Illustration: ReLU in Action\n",
    "\n",
    "Negative values (shown in blue) become zero, while positive values (red) pass through unchanged. The mask shows which values were zeroed out.\n",
    "\n",
    "![ReLU: Zeroing Negative Activations](images/relu_heatmap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c8081",
   "metadata": {},
   "source": [
    "## 3. Max Pooling\n",
    "\n",
    "Reduces the spatial dimensions by taking the maximum value in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077f0677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool: Input (1, 1, 2, 2) -> Output (1, 1, 1, 1)\n",
      "MaxPool(2x2):\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "def max_pool_forward(input, kernel_size=2, stride=2):\n",
    "    B, C, H, W = input.shape\n",
    "\n",
    "    H_out = (H - kernel_size) // stride + 1\n",
    "    W_out = (W - kernel_size) // stride + 1\n",
    "\n",
    "    out = np.zeros((B, C, H_out, W_out))\n",
    "\n",
    "    print(f\"MaxPool: Input {input.shape} -> Output {out.shape}\")\n",
    "\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            for h in range(H_out):\n",
    "                for w in range(W_out):\n",
    "                    h_start = h * stride\n",
    "                    w_start = w * stride\n",
    "                    patch = input[b, c, h_start:h_start+kernel_size, w_start:w_start+kernel_size]\n",
    "                    out[b, c, h, w] = np.max(patch)\n",
    "    return out\n",
    "\n",
    "# Verification\n",
    "x_pool = np.array([[1, 2], [3, 4]]).reshape(1, 1, 2, 2)\n",
    "print(f\"MaxPool(2x2):\\n{max_pool_forward(x_pool, 2, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c26dd3",
   "metadata": {},
   "source": [
    "### Illustration: MaxPool in Action\n",
    "\n",
    "Each 2×2 block is reduced to its maximum value, halving the spatial dimensions. The green cells in the rightmost panel show which values were selected as the maximum in each block.\n",
    "\n",
    "![MaxPool: Spatial Downsampling via Local Maxima](images/maxpool_heatmap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce6400",
   "metadata": {},
   "source": [
    "## 4. Integration\n",
    "\n",
    "Let's pass a random input through our manual layers to observe volume compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c856d66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Forward Pass ---\n",
      "Conv2d: Input (1, 1, 28, 28) -> Output (1, 32, 26, 26)\n",
      "MaxPool: Input (1, 32, 26, 26) -> Output (1, 32, 13, 13)\n",
      "\n",
      "--- Shapes ---\n",
      "Input:    (1, 1, 28, 28)\n",
      "Conv:     (1, 32, 26, 26) (28 -> 26)\n",
      "ReLU:     (1, 32, 26, 26)\n",
      "Pool:     (1, 32, 13, 13) (26 -> 13)\n"
     ]
    }
   ],
   "source": [
    "# Random Input Image (1 batch, 1 channel, 28x28)\n",
    "x = np.random.randn(1, 1, 28, 28)\n",
    "\n",
    "# Weights for Conv Layer (32 filters, 1 input channel, 3x3 kernel)\n",
    "w = np.random.randn(32, 1, 3, 3)\n",
    "\n",
    "print(\"--- Forward Pass ---\")\n",
    "# 1. Convolution\n",
    "out_conv = conv2d_forward(x, w)\n",
    "\n",
    "# 2. ReLU\n",
    "out_relu = relu_forward(out_conv)\n",
    "\n",
    "# 3. MaxPool\n",
    "out_pool = max_pool_forward(out_relu, 2, 2)\n",
    "\n",
    "print(\"\\n--- Shapes ---\")\n",
    "print(f\"Input:    {x.shape}\")\n",
    "print(f\"Conv:     {out_conv.shape} (28 -> 26)\")\n",
    "print(f\"ReLU:     {out_relu.shape}\")\n",
    "print(f\"Pool:     {out_pool.shape} (26 -> 13)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3541e4",
   "metadata": {},
   "source": [
    "### Illustration: Full CNN Pipeline\n",
    "\n",
    "A digit passes through the complete pipeline: **Conv2d** (with 8 different kernels) → **ReLU** (zeroing negatives) → **MaxPool** (spatial downsampling). Each column shows a different filter's response at each stage.\n",
    "\n",
    "![Full CNN Pipeline: Input → Conv → ReLU → MaxPool](images/full_pipeline.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
